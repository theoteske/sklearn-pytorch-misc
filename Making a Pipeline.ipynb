{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e188ea20",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate how to use the `Pipeline` class in sklearn to streamline our data processing. First, we load in the Breast Cancer Wisconsin dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3902dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data',\n",
    "    header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47320b82",
   "metadata": {},
   "source": [
    "Next, we inspect the dataset to see what kind of preprocessing we need to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101a5a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       569 non-null    int64  \n",
      " 1   1       569 non-null    object \n",
      " 2   2       569 non-null    float64\n",
      " 3   3       569 non-null    float64\n",
      " 4   4       569 non-null    float64\n",
      " 5   5       569 non-null    float64\n",
      " 6   6       569 non-null    float64\n",
      " 7   7       569 non-null    float64\n",
      " 8   8       569 non-null    float64\n",
      " 9   9       569 non-null    float64\n",
      " 10  10      569 non-null    float64\n",
      " 11  11      569 non-null    float64\n",
      " 12  12      569 non-null    float64\n",
      " 13  13      569 non-null    float64\n",
      " 14  14      569 non-null    float64\n",
      " 15  15      569 non-null    float64\n",
      " 16  16      569 non-null    float64\n",
      " 17  17      569 non-null    float64\n",
      " 18  18      569 non-null    float64\n",
      " 19  19      569 non-null    float64\n",
      " 20  20      569 non-null    float64\n",
      " 21  21      569 non-null    float64\n",
      " 22  22      569 non-null    float64\n",
      " 23  23      569 non-null    float64\n",
      " 24  24      569 non-null    float64\n",
      " 25  25      569 non-null    float64\n",
      " 26  26      569 non-null    float64\n",
      " 27  27      569 non-null    float64\n",
      " 28  28      569 non-null    float64\n",
      " 29  29      569 non-null    float64\n",
      " 30  30      569 non-null    float64\n",
      " 31  31      569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "825fc171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7        8    \n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  \\\n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
       "5    843786  M  12.45  15.70   82.57   477.1  0.12780  0.17000  0.15780   \n",
       "6    844359  M  18.25  19.98  119.60  1040.0  0.09463  0.10900  0.11270   \n",
       "7  84458202  M  13.71  20.83   90.20   577.9  0.11890  0.16450  0.09366   \n",
       "8    844981  M  13.00  21.82   87.50   519.8  0.12730  0.19320  0.18590   \n",
       "9  84501001  M  12.46  24.04   83.97   475.9  0.11860  0.23960  0.22730   \n",
       "\n",
       "        9   ...     22     23      24      25      26      27      28      29   \n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654  \\\n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "5  0.08089  ...  15.47  23.75  103.40   741.6  0.1791  0.5249  0.5355  0.1741   \n",
       "6  0.07400  ...  22.88  27.66  153.20  1606.0  0.1442  0.2576  0.3784  0.1932   \n",
       "7  0.05985  ...  17.06  28.14  110.60   897.0  0.1654  0.3682  0.2678  0.1556   \n",
       "8  0.09353  ...  15.49  30.73  106.20   739.3  0.1703  0.5401  0.5390  0.2060   \n",
       "9  0.08543  ...  15.09  40.68   97.65   711.4  0.1853  1.0580  1.1050  0.2210   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "5  0.3985  0.12440  \n",
       "6  0.3063  0.08368  \n",
       "7  0.3196  0.11510  \n",
       "8  0.4378  0.10720  \n",
       "9  0.4366  0.20750  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf3f7a9",
   "metadata": {},
   "source": [
    "We can see that the zeroth column is some kind of unique identifier, while the first column is the class label, where `M` denotes a malignant tumor and `B` denotes a benign tumor. We will now form NumPy arrays for the features and class labels and encode the class labels as $1$ and $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65afc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#create numpy arrays\n",
    "X = df.loc[:, 2:].values\n",
    "y = df.loc[:, 1]\n",
    "\n",
    "#encode class labels, M is 1 and B is 0\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4816d791",
   "metadata": {},
   "source": [
    "Next, we want to perform an $80\\%$-$20\\%$ stratified train-test split, which will ensure that the test set and training set have a similar proportion of malignant and benign instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00795242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#perform 80-20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71d21cc",
   "metadata": {},
   "source": [
    "Next, we can create a pipeline chaining together the `StandardScaler`, `LinearDiscriminantAnalysis`, and `LogisticRegression` classes that will standardize our feature set, perform dimensionality reduction via LDA, and then use a logistic regression estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec4a938a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#make pipeline\n",
    "pipe_lr = make_pipeline(StandardScaler(), LDA(n_components=1), LogisticRegression())\n",
    "\n",
    "#fit our pipeline to the data\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "#see how it performs on the dataset\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "test_acc = pipe_lr.score(X_test, y_test)\n",
    "print(\"Test accuracy: {}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

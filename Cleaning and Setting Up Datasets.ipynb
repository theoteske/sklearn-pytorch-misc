{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b8d782",
   "metadata": {},
   "source": [
    "# Dealing with Missing Data\n",
    "\n",
    "If we have blank spaces, NaN (not a number), or NULL values in the dataset, we need to address this for our models to work.\n",
    "\n",
    "### Identifying Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28210fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     W     X     Y     Z\n",
       "0  1.0   NaN   3.0   4.0\n",
       "1  5.0   6.0   NaN   8.0\n",
       "2  9.0  10.0  11.0  12.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO #allows us to read string as input from hard drive\n",
    "\n",
    "#make sample csv file\n",
    "csv_data = \\\n",
    "'''\n",
    "W,X,Y,Z\n",
    "1.0,,3.0,4.0\n",
    "5.0,6.0,,8.0\n",
    "9.0,10.0,11.0,12.0\n",
    "'''\n",
    "\n",
    "#read into a dataframe\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5465fa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "W    0\n",
       "X    1\n",
       "Y    1\n",
       "Z    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count number of missing values per column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f4f04",
   "metadata": {},
   "source": [
    "Note that when working with `sklearn`, we prefer to use `NumPy` arrays rather than `pandas` dataframes. We can always access the underlying `NumPy` array for a dataframe by accessing the values attribute `df.values` before feeding it into an `sklearn` estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15242e1",
   "metadata": {},
   "source": [
    "### Eliminating Missing Values\n",
    "\n",
    "We can use the `dropna` method from the `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56b2f05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     W     X     Y     Z\n",
       "2  9.0  10.0  11.0  12.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop rows that contain a missing value\n",
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ce89fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     W     Z\n",
       "0  1.0   4.0\n",
       "1  5.0   8.0\n",
       "2  9.0  12.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop features that contain a missing value\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4c2ade",
   "metadata": {},
   "source": [
    "The `dropna` method also takes various parameters which can be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9df55231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     W     X     Y     Z\n",
       "0  1.0   NaN   3.0   4.0\n",
       "1  5.0   6.0   NaN   8.0\n",
       "2  9.0  10.0  11.0  12.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only drop rows where all features are NaN\n",
    "df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a20ea473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     W     X     Y     Z\n",
       "2  9.0  10.0  11.0  12.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop rows that have fewer than 4 actual values\n",
    "df.dropna(thresh=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eed531f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     W     X     Y     Z\n",
       "0  1.0   NaN   3.0   4.0\n",
       "2  9.0  10.0  11.0  12.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only drop rows where NaN appears in a specific column\n",
    "df.dropna(subset=['Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f6b1a",
   "metadata": {},
   "source": [
    "### Imputing Missing Values\n",
    "\n",
    "Often dropping instances that contain missing values eliminates too much useful data. Instead, we can use *interpolation* techniques to estimate the missing values from other training examples in the dataset.\n",
    "\n",
    "A common method is *mean imputation*, where we replace the missing value by the mean value of the feature. We can do this using the `SimpleImputer` class in the `sklearn` library. Other options for the strategy parameter are `'median'` (if the data are skewed so that this is a better predictor) and `'most_frequent'` (this is useful for categorical data, for example, if the feature is an encoding of color names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e04ffd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  8.,  3.,  4.],\n",
       "       [ 5.,  6.,  7.,  8.],\n",
       "       [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "#create an instance of SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(df.values)\n",
    "imputed_data = imputer.transform(df.values)\n",
    "imputed_data #mean of 2nd feature is 8, mean of 3rd feature is 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888c4ff",
   "metadata": {},
   "source": [
    "Alternatively, we can just use the `fillna` method from the `pandas` library to fill every NaN with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f40000ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     W     X     Y     Z\n",
       "0  1.0   8.0   3.0   4.0\n",
       "1  5.0   6.0   7.0   8.0\n",
       "2  9.0  10.0  11.0  12.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a0adc",
   "metadata": {},
   "source": [
    "There is also a `KNNImputer` class in the `sklearn` library which imputes missing values using the k-Nearest Neighbors approach. Each missing feature is imputed using values from `n_neighbors` nearest neighbors that have a value for the feature. The feature of the neighbors are averaged uniformly or weighted by distance to each neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "744ac366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  8.,  3.,  4.],\n",
       "       [ 5.,  6.,  7.,  8.],\n",
       "       [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=2, weights='uniform')\n",
    "imputer.fit_transform(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadaf6a4",
   "metadata": {},
   "source": [
    "The `SimpleImputer` class is part of the transformer API in `sklearn`, which contains classes to help with data transformation. In general, these classes have two main methods: the `fit` method by which the transformer (NOT the neural network architecture) learns its parameters from a dataset, and the `transform` method where it uses those parameters to transform a dataset. Any dataset that is transformed must have the same number of features as the dataset that was used to fit the transformer.\n",
    "\n",
    "For example, given a training set `X_train` and a test set `X_test`, if we want to transform our data, it's best practice to learn the parameters of the training dataset and then transform both the training and test set according to these parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddba7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = Transformer(param_1=x, param_2=y)\n",
    "tf.fit(X_train)\n",
    "tf.transform(X_train)\n",
    "tf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f8403",
   "metadata": {},
   "source": [
    "# Handling Categorical Data\n",
    "\n",
    "We need to distinguish between *ordinal* and *nominal* features when considering categorical features. Ordinal features have a natural ordering, whereas nominal features have no order. For example, t-shirt size is an ordinal feature, while t-shirt color is a nominal feature.\n",
    "\n",
    "In general, class labels are always considered to be nominal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a38cf07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel\n",
       "0  green    M   10.1     class2\n",
       "1   blue    L   13.5     class1\n",
       "2    red   XL   15.1     class1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new dataframe\n",
    "df = pd.DataFrame([\n",
    "    ['green', 'M', 10.1, 'class2'],\n",
    "    ['blue', 'L', 13.5, 'class1'],\n",
    "    ['red', 'XL', 15.1, 'class1']\n",
    "])\n",
    "df.columns = ['color', 'size', 'price', 'classlabel']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac0ec65",
   "metadata": {},
   "source": [
    "### Mapping Ordinal Features\n",
    "\n",
    "Suppose we want to encode the ordinal variable above (size) into integers; we can do this by defining a dictionary describing the conversion that creates the correct order and using the `map` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3c81f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price classlabel\n",
       "0  green     0   10.1     class2\n",
       "1   blue     1   13.5     class1\n",
       "2    red     2   15.1     class1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map according to mapping dict\n",
    "size_map = {'M':0, 'L':1, 'XL':2}\n",
    "df['size'] = df['size'].map(size_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4def5a",
   "metadata": {},
   "source": [
    "If we want to recover the original size labels from the newly transformed feature, we can simply define an inverse mapping dict and follow the same procedure as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ffb540a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     M\n",
       "1     L\n",
       "2    XL\n",
       "Name: size, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##use dict comprehension to reverse the original dict\n",
    "inverse_map = {value:index for index, value in size_map.items()}\n",
    "df['size'].map(inverse_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b401d4dc",
   "metadata": {},
   "source": [
    "### Encoding Ordinal Features\n",
    "\n",
    "Suppose we have an ordinal feature where the numerical difference between the values it takes is unknown or ill-defined. Then we can encode the values using a *threshold encoding* with binary values.\n",
    "\n",
    "The idea is to create subsets of values. For example, in terms of an adult's education level, given the set of values {high school, college, law school, medical school}, it might make sense to create the subsets {high school}, {high school, college}, {high school, college, law school}, {high school, college, medical school}. We are assuming that if someone has completed college, they have also completed high school. Similarly, we assume that if someone has gone to law school, then it is unlikely that they have also completed medical school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c887d448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "      <th>size &gt; M</th>\n",
       "      <th>size &gt; L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red</td>\n",
       "      <td>15.1</td>\n",
       "      <td>class1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  price classlabel  size > M  size > L\n",
       "0  green   10.1     class2         0         0\n",
       "1   blue   13.5     class1         1         0\n",
       "2    red   15.1     class1         1         1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recreate data frame\n",
    "df = pd.DataFrame([\n",
    "    ['green', 'M', 10.1, 'class2'],\n",
    "    ['blue', 'L', 13.5, 'class1'],\n",
    "    ['red', 'XL', 15.1, 'class1']\n",
    "])\n",
    "df.columns = ['color', 'size', 'price', 'classlabel']\n",
    "\n",
    "#create binary-valued features for size subsets\n",
    "df['size > M'] = df['size'].apply(lambda x: 1 if x in {'L', 'XL'} else 0)\n",
    "df['size > L'] = df['size'].apply(lambda x: 1 if x == 'XL' else 0)\n",
    "del df['size']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e29c47e",
   "metadata": {},
   "source": [
    "### Encoding Class Labels\n",
    "\n",
    "Most machine learning libraries require class labels to be encoded as integer values. So, we do the same thing as we did for ordinal variables, but we can simply enumerate the unique class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "032db1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price  classlabel\n",
       "0  green     0   10.1           1\n",
       "1   blue     1   13.5           0\n",
       "2    red     2   15.1           0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map = {label:index for index, label in enumerate(np.unique(df['classlabel']))}\n",
    "df['classlabel'] = df['classlabel'].map(class_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3de738",
   "metadata": {},
   "source": [
    "Alternatively, we can use the `LabelEncoder` class from `sklearn` which is designed to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b41612e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#create an instance of the LabelEncoder class\n",
    "labe = LabelEncoder()\n",
    "labe.fit_transform(df['classlabel'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d356ed",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "For nominal variables other than class labels, if we do the same thing we did above, we will end up imposing an ordering on the values that the feature takes. This may influence the classification algorithm adversely and unnecessarily; as a result, we prefer to employ *one-hot encoding*. We use binary values to encode each value of the categorical feature, and we thereby replace the original feature with `len(np.unique(feature))` many binary-valued features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c0b421c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#make a numpy array for the non-classlabel features\n",
    "X = df[['color', 'size', 'price']].values\n",
    "\n",
    "#use sklearn class OneHotEncoder\n",
    "color_ohe = OneHotEncoder()\n",
    "color_ohe.fit_transform(X[:,0].reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f1d09f",
   "metadata": {},
   "source": [
    "If we want to transform multiple columns at once according to different encodings, we can use the `ColumnTransformer` class in the `sklearn` library. It accepts a list of `(name, transformer, column(s))` tuples, where `column(s)` is a list of columns to which you want to apply the specified transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82691594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  1. ,  0. ,  0. , 10.1],\n",
       "       [ 1. ,  0. ,  0. ,  1. , 13.5],\n",
       "       [ 0. ,  0. ,  1. ,  2. , 15.1]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ctr = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(), [0]),\n",
    "    ('nothing', 'passthrough', [1,2])\n",
    "])\n",
    "\n",
    "ctr.fit_transform(X).astype(float) #why do we want this to be floats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e2b6b1",
   "metadata": {},
   "source": [
    "An even easier way to implement the same idea is by using the `get_dummies` function in the `pandas` library. Applied to a `DataFrame`, the `get_dummies` method will only convert string columns and will leave all other columns unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a40862ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size  price  color_blue  color_green  color_red\n",
       "0     0   10.1         0.0          1.0        0.0\n",
       "1     1   13.5         1.0          0.0        0.0\n",
       "2     2   15.1         0.0          0.0        1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df[['color', 'size', 'price']], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0fa411",
   "metadata": {},
   "source": [
    "However, we need to note that one-hot encoding introduces *multicollinearity*, which is a problem for some algorithms (such as those that require matrix inversion). To reduce correlation, we remove one feature column from the one-hot encoded array. Note that this only removes redundant information (because if an instance does not take any of $K-1$ values, it must be take the remaining value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4486c0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size  price  color_green  color_red\n",
       "0   0.0   10.1          1.0        0.0\n",
       "1   1.0   13.5          0.0        0.0\n",
       "2   2.0   15.1          0.0        1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df[['color', 'size', 'price']], dtype=float, drop_first=True).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9970b070",
   "metadata": {},
   "source": [
    "In order to drop a redundant column via the `OneHotEncoder`, we need to set `drop='first'` and set `categories='auto'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17c93061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  0. ,  0. , 10.1],\n",
       "       [ 0. ,  0. ,  1. , 13.5],\n",
       "       [ 0. ,  1. ,  2. , 15.1]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_ohe = OneHotEncoder(categories='auto', drop='first')\n",
    "\n",
    "ctr = ColumnTransformer([\n",
    "    ('onehot', color_ohe, [0]),\n",
    "    ('nothing', 'passthrough', [1,2])\n",
    "])\n",
    "\n",
    "ctr.fit_transform(X).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df062191",
   "metadata": {},
   "source": [
    "# Partitioning a Dataset into Training and Test Sets\n",
    "\n",
    "If we are dividing a dataset into training and test datasets, we have to keep in mind that we are withholding valuable information that the learning algorithm could benefit from. Thus, we donâ€™t want to allocate too much information to the test set. However, the smaller the test set, the more inaccurate the estimation of the generalization error. Dividing a dataset into training and test datasets is all about balancing this tradeoff. In practice, the most commonly used splits are 60:40, 70:30, or 80:20, depending on the size of the initial dataset. However, for large datasets, 90:10 or 99:1 splits are also common and appropriate. For example, if the dataset contains more than 100,000 training examples, it might be fine to withhold only 10,000 examples for testing in order to get a good estimate of the generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28008de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class label</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium   \n",
       "0            1    14.23        1.71  2.43               15.6        127  \\\n",
       "1            1    13.20        1.78  2.14               11.2        100   \n",
       "2            1    13.16        2.36  2.67               18.6        101   \n",
       "3            1    14.37        1.95  2.50               16.8        113   \n",
       "4            1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins   \n",
       "0           2.80        3.06                  0.28             2.29  \\\n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load wine dataset from UCI ML archive\n",
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash',\\\n",
    "                   'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols',\\\n",
    "                   'Proanthocyanins', 'Color intensity', 'Hue',\\\n",
    "                   'OD280/OD315 of diluted wines', 'Proline']\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b704bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#separate out features from class labels\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "\n",
    "#do 70-30 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d658e62",
   "metadata": {},
   "source": [
    "In the above, setting `stratify=y` ensures that both the training and test sets have the same class proportions as the original data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5016924e",
   "metadata": {},
   "source": [
    "# Bringing Features onto the Same Scale\n",
    "\n",
    "remember to fit scaler on training set then transform test set using those same parameters\n",
    "\n",
    "Almost every machine learning algorithm requires feature scaling for it to work optimally (decision trees and random forests are two of the few which do not as they are scale-invariant). Having all features on the same scale ensures that the training process is not dominated by a small number of features with disproportionately large scale.\n",
    "\n",
    "There are two common ways to accompish this: *normalization* and *standardization*. In general, normalization involves scaling features to be within the range $[0, 1]$ with an application of *min-max scaling*. To calculate a normalized version of the feature $X$, for every observation $x^{(i)}\\in X$ we compute\n",
    "$$\n",
    "x^{(i)}_{norm} = \\frac{x^{(i)} - x_{min}}{x_{max} - x_{min}},\n",
    "$$\n",
    "where $x_{max} = \\max_{x\\in X} x$ and $x_{min}$ is defined similarly. We can implement this with `sklearn` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154ac450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af45c5f1",
   "metadata": {},
   "source": [
    "For many machine learning algorithms, it is likely more effective to perform standardization, which entails centering the features at mean zero with standard deviation one. This is helpful many algorithms (including gradient descent) as it is common to initialize weights to zero or small random values near zero. Note that standardization does NOT transform the distribution of the data, so the new features will not be normally distributed unless the initial data are normally distributed. To standardize $X$ we compute\n",
    "$$\n",
    "x_{std}^{(i)} = \\frac{x^{(i)}-\\mu_{X}}{\\sigma_{X}},\n",
    "$$\n",
    "where $\\mu_X$ is the mean of the feature $X$ and $\\sigma_X$ is its standard deviation. We can implement standardization with `sklearn` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6ded110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_std = ss.fit_transform(X_train)\n",
    "X_test_std = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d890957e",
   "metadata": {},
   "source": [
    "It's important to note that we always fit the scaler only once, on the training features. We then transform any new data (such as the test set) using those parameters.\n",
    "\n",
    "Another option is to use `RobustScaler`, which operates on each feature independently and removes the median value before scaling according to the first and third quartiles of the feature, so that extreme values and outliers become less pronounced. This method is recommended for small datasets that contain many outliers, and for machine learning algorithms that are prone to overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
